{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "import operator\n",
    "import itertools\n",
    "import pickle\n",
    "import tqdm\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import simpleclock\n",
    "import sklearn.metrics\n",
    "import sklearn.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(tokenize = \"spacy\",\n",
    "                            include_lengths=True)\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_, data_test = torchtext.datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = data_train_.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 17500 examples.\n",
      "validation data: 7500 examples.\n",
      "test data: 25000 examples.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"training data: {len(data_train)} examples.\n",
    "validation data: {len(data_valid)} examples.\n",
    "test data: {len(data_test)} examples.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_MAX_SIZE = 50000\n",
    "TEXT.build_vocab(data_train, max_size=VOCAB_MAX_SIZE, vectors=\"glove.6B.100d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'neg': 0, 'pos': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.build_vocab(data_train)\n",
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train, iter_valid, iter_test = \\\n",
    "    torchtext.data.BucketIterator.splits((data_train, data_valid, data_test),\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  device=DEVICE,\n",
    "                                  sort_within_batch=True,\n",
    "                                  sort_key=lambda ex: len(ex.text),\n",
    "                                  sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, n_vocab, embedding_dim, hidden_dim, output_dim, dropout, bidirectional,\n",
    "                 n_layers, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        num_dir = 2 if bidirectional else 1\n",
    "        self.embedding = torch.nn.Embedding(n_vocab, embedding_dim, padding_idx=pad_idx)\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim,\n",
    "                                 bidirectional=bidirectional,\n",
    "                                 num_layers=n_layers,\n",
    "                                 dropout=dropout)\n",
    "        self.fc = torch.nn.Linear(hidden_dim * num_dir, output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_lengths):\n",
    "        input, lengths = input_lengths\n",
    "        torch.nn.utils.rnn.pack_padded_sequence(input, lengths)\n",
    "        embedded = self.embedding(input)  # ((sent_len, batch), emb_dim)\n",
    "        packed_output, (hidden, cell) = self.rnn(embedded)  # hidden: (num_layers * num_directions,\n",
    "                                                            #          batch, hidden_size * num_directions)\n",
    "        hidden = (torch.cat([hidden[-2, :, :], hidden[-1, :, :]], dim=1)\n",
    "                  if self.bidirectional else hidden).squeeze(0)  # (batch, hidden_size * num_directions)\n",
    "        return self.sigmoid(self.fc(self.dropout(hidden)))  # (batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "N_VOCAB = len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    \"n_vocab\": N_VOCAB,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"output_dim\": 1,\n",
    "    \"dropout\": 0.5,\n",
    "    \"bidirectional\": True,\n",
    "    \"n_layers\": 2,\n",
    "    \"pad_idx\": PAD_IDX,\n",
    "}\n",
    "\n",
    "def default_model(**kwargs):\n",
    "    _d = {}\n",
    "    _d.update(DEFAULT_PARAMS)\n",
    "    _d.update(kwargs)\n",
    "    return RNN(**_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_init(model, criterion, device=DEVICE, learn_embedding_param=True):\n",
    "    model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(model.embedding_dim)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(model.embedding_dim)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if name == \"embedding.weight\":\n",
    "            param.requires_grad = learn_embedding_param\n",
    "    \n",
    "    print(\"The model has {:,} trainable parameters\"\n",
    "         .format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    return model, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_pred(output):\n",
    "    return torch.round(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    correct = (preds == y).float()  # convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_from_output(output, target):\n",
    "    return accuracy(output_to_pred(output), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nntraining.pytorch.supervised import AccLossMeasurer, do_training, evaluate, is_max_of\n",
    "from nntraining.pytorch.text import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = default_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,631,241 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model, criterion = pseudo_init(model, torch.nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not saving best model.\n",
      "Starting training: 20 epochs.\n",
      "Epoch: 1.. T, V acc: 58.3%, 59.2%. Took 12.45s. (+)\n",
      "Epoch: 2.. T, V acc: 67.2%, 52.6%. Took 12.34s.\n",
      "Epoch: 3.. T, V acc: 77.3%, 71.1%. Took 12.33s. (+)\n",
      "Epoch: 4.. T, V acc: 82.8%, 68.4%. Took 12.35s.\n",
      "Epoch: 5.. T, V acc: 89.7%, 81.6%. Took 12.41s. (+)\n",
      "Epoch: 6.. T, V acc: 79.1%, 47.4%. Took 12.51s.\n",
      "Epoch: 7.. T, V acc: 65.3%, 52.6%. Took 12.68s.\n",
      "Epoch: 8.. T, V acc: 76.2%, 86.8%. Took 12.39s. (+)\n",
      "Epoch: 9.. T, V acc: 90.6%, 81.6%. Took 12.36s.\n",
      "Epoch: 10. T, V acc: 94.6%, 85.5%. Took 12.34s.\n",
      "Epoch: 11. T, V acc: 85.8%, 81.6%. Took 12.29s.\n",
      "Epoch: 12. T, V acc: 94.9%, 89.5%. Took 12.35s. (+)\n",
      "Epoch: 13. T, V acc: 94.7%, 52.6%. Took 12.32s.\n",
      "Epoch: 14. T, V acc: 91.5%, 75.0%. Took 12.25s.\n",
      "Epoch: 15. T, V acc: 96.9%, 77.6%. Took 12.33s.\n",
      "Epoch: 16. T, V acc: 98.0%, 80.3%. Took 12.40s.\n",
      "Epoch: 17. T, V acc: 98.6%, 78.9%. Took 12.38s.\n",
      "Epoch: 18. T, V acc: 98.8%, 76.3%. Took 12.36s.\n",
      "Epoch: 19. T, V acc: 99.0%, 77.6%. Took 12.40s.\n",
      "Epoch: 20. T, V acc: 99.0%, 80.3%. Took 12.35s.\n",
      "Trained imdbtest, 20 epochs, for: 247.60s\n"
     ]
    }
   ],
   "source": [
    "training_info = do_training(model,\n",
    "                            \"imdbtest\", \n",
    "                            iter_train, \n",
    "                            iter_valid, \n",
    "                            optimizer, \n",
    "                            criterion,\n",
    "                            n_epochs=20,\n",
    "                            get_input=operator.attrgetter(\"text\"),\n",
    "                            get_target=operator.attrgetter(\"label\"),\n",
    "                            fun_is_best=is_max_of(\"acc\"),\n",
    "                            measurer_getter=AccLossMeasurer.getter(accuracy_from_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(model, TEXT.vocab.stoi, nlp.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021064248867332935"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor(\"This film is terrible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99488765001297"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor(\"This is a great movie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.7321428656578064, 'loss': 0.209058940410614}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, iter_test, criterion, operator.attrgetter(\"text\"), operator.attrgetter(\"label\"),\n",
    "         AccLossMeasurer(accuracy_from_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
