{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import collections\n",
    "import operator\n",
    "import itertools\n",
    "import pickle\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import simpleclock\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.abspath(''), \"data_cine_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(tokenize = \"spacy\",\n",
    "                            tokenizer_language=\"fr_core_news_sm\",\n",
    "                            include_lengths=True)\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.float, use_vocab=False, preprocessing=lambda x: float(x) / 5)\n",
    "# labels are linearly rescaled to a 0-1 range\n",
    "# todo: test if preprocessing data before isn't faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchtext.data.TabularDataset(path=data_path,\n",
    "                                        format=\"CSV\",\n",
    "                                        fields={\"critique\": (\"input\", TEXT), \"note\": (\"target\", LABEL)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = data_train.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 36057 examples.\n",
      "validation data: 15453 examples.\n",
      "test data: 22076 examples.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"training data: {len(data_train)} examples.\n",
    "validation data: {len(data_valid)} examples.\n",
    "test data: {len(data_test)} examples.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torchtext.vocab.Vectors(\"cc.fr.300.vec\", os.path.join(os.path.expanduser(\"~\"), \"Downloads\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_MAX_SIZE = 50000\n",
    "TEXT.build_vocab(data_train, max_size=VOCAB_MAX_SIZE, vectors=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train, iter_valid, iter_test = \\\n",
    "    torchtext.data.BucketIterator.splits(datasets=(data_train, data_valid, data_test),\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         device=DEVICE,\n",
    "                                         sort_within_batch=True,\n",
    "                                         sort_key=lambda example: len(example.input),\n",
    "                                         sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, n_vocab, embedding_dim, hidden_dim, output_dim, dropout, bidirectional,\n",
    "                 n_layers, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        num_dir = 2 if bidirectional else 1\n",
    "        self.embedding = torch.nn.Embedding(n_vocab, embedding_dim, padding_idx=pad_idx)\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim,\n",
    "                                 bidirectional=bidirectional,\n",
    "                                 num_layers=n_layers)\n",
    "        self.fc = torch.nn.Linear(hidden_dim * num_dir, output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_lengths):\n",
    "        input, lengths = input_lengths\n",
    "        torch.nn.utils.rnn.pack_padded_sequence(input, lengths)\n",
    "        embedded = self.embedding(input)  # ((sent_len, batch), emb_dim)\n",
    "        packed_output, (hidden, cell) = self.rnn(embedded)  # hidden: (num_layers * num_directions,\n",
    "                                                            #          batch, hidden_size * num_directions)\n",
    "        hidden = (torch.cat([hidden[-2, :, :], hidden[-1, :, :]], dim=1)\n",
    "                  if self.bidirectional else hidden).squeeze(0)  # (batch, hidden_size * num_directions)\n",
    "        return self.sigmoid(self.fc(self.dropout(hidden)))  # (batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "N_VOCAB = len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    \"n_vocab\": N_VOCAB,\n",
    "    \"embedding_dim\": 300,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"output_dim\": 1,\n",
    "    \"dropout\": 0.5,\n",
    "    \"bidirectional\": True,\n",
    "    \"n_layers\": 1,\n",
    "    \"pad_idx\": PAD_IDX,\n",
    "}\n",
    "\n",
    "def default_model(**kwargs):\n",
    "    _d = {}\n",
    "    _d.update(DEFAULT_PARAMS)\n",
    "    _d.update(kwargs)\n",
    "    return RNN(**_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_init(model, criterion, device=DEVICE, learn_embedding_param=True):\n",
    "    model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(model.embedding_dim)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(model.embedding_dim)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if name == \"embedding.weight\":\n",
    "            param.requires_grad = learn_embedding_param\n",
    "    \n",
    "    print(\"The model has {:,} trainable parameters\"\n",
    "         .format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    return model, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_pred(output):\n",
    "    return (output * 10).round() / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    correct = (preds == y).float()  # convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch.input).squeeze(1)\n",
    "        loss = criterion(output, batch.target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = accuracy(output_to_pred(output), batch.target * 5)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "      \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            output = model(batch.input).squeeze(1)\n",
    "            loss = criterion(output, batch.target)\n",
    "            acc = accuracy(output_to_pred(output), batch.target * 5)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainInfo:\n",
    "    def __init__(self, valid={}, train={}):\n",
    "        self.valid = collections.defaultdict(lambda: [])\n",
    "        self.valid.update(valid)\n",
    "        self.train = collections.defaultdict(lambda: [])\n",
    "        self.train.update(train)\n",
    "    \n",
    "    def save(self, path):\n",
    "        packed = {\n",
    "            \"valid\": dict(self.valid),\n",
    "            \"train\": dict(self.train),\n",
    "        }\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(packed, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            packed = pickle.load(f)\n",
    "            return cls(valid=packed[\"valid\"],\n",
    "                       train=packed[\"train\"])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _dict_to_repr(d):\n",
    "        return dict(map(lambda k_v: (k_v[0], f\"{len(k_v[1])} elements\"), d.items()))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return pprint.pformat({\"valid\": self._dict_to_repr(self.valid),\n",
    "                     \"train\": self._dict_to_repr(self.train),})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(model, name, iter_train, iter_valid, optimizer, criterion, fun_train,\n",
    "                fun_eval, n_epochs=100, train_info=None):\n",
    "\n",
    "    clock = simpleclock.Clock.started()\n",
    "    torch.cuda.empty_cache()\n",
    "    train_info = train_info if train_info is not None else TrainInfo()\n",
    "    best_valid_loss = min(train_info.valid[\"loss\"]) if train_info.valid[\"loss\"] else float(\"inf\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        clock.elapsed_since_start.call()  # meh\n",
    "\n",
    "        train_loss, train_acc = fun_train(model, iter_train, optimizer, criterion)\n",
    "        valid_loss, valid_acc = fun_eval(model, iter_valid, criterion)\n",
    "        \n",
    "        is_best = valid_loss < best_valid_loss\n",
    "        print(\"Epoch: {e:<3}. T, V acc: {train:.1f}%, {valid:.1f}%. Took {t:.2f}s.\"\n",
    "             .format(e=epoch + 1,\n",
    "                     train=100 * train_acc,\n",
    "                     valid=100 * valid_acc,\n",
    "                     t=clock.elapsed_since_last_call())\n",
    "             + (\" (+)\" if is_best else \"\")\n",
    "             )\n",
    "        \n",
    "        train_info.train[\"loss\"].append(train_loss)\n",
    "        train_info.valid[\"loss\"].append(valid_loss)\n",
    "\n",
    "        if is_best:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f\"{name}.pt\")\n",
    "\n",
    "    clock.elapsed_since_start.print(f\"Trained {name}, {n_epochs} epochs, for\")\n",
    "    return train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSet:\n",
    "    def __init__(self, model, name, iter_train, iter_valid,\n",
    "                 fun_optimizer, fun_criterion, fun_train, fun_eval,\n",
    "                 device=DEVICE, n_epochs=100):\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.iter_train = iter_train\n",
    "        self.iter_valid = iter_valid\n",
    "        self.fun_optimizer = fun_optimizer\n",
    "        self.fun_criterion = fun_criterion\n",
    "        self.fun_train = fun_train\n",
    "        self.fun_eval = fun_eval\n",
    "        self.n_epochs = n_epochs\n",
    "        self.device = device\n",
    "        \n",
    "        self.optimizer = None\n",
    "        self.criterion = None\n",
    "        \n",
    "    def init(self, learn_embedding_param=True):\n",
    "        self.model, self.criterion = pseudo_init(self.model, self.fun_criterion(), self.device,\n",
    "                                                 learn_embedding_param=learn_embedding_param)\n",
    "        self.optimizer = self.fun_optimizer(self.model.parameters())\n",
    "    \n",
    "    def do_training(self):\n",
    "        if self.optimizer is None or self.criterion is None:\n",
    "            raise Exception(\"It looks like an init is needed: optimizer or criterion is None\")\n",
    "        return do_training(model=self.model,\n",
    "                           name=self.name,\n",
    "                           iter_train=self.iter_train,\n",
    "                           iter_valid=self.iter_valid,\n",
    "                           optimizer=self.optimizer,\n",
    "                           criterion=self.criterion,\n",
    "                           fun_train=self.fun_train,\n",
    "                           fun_eval=self.fun_eval,\n",
    "                           n_epochs=self.n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/loading utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocab_embedding(path, vocab, embedding):\n",
    "    with open(path, \"w\") as f:\n",
    "        for word, vector in tqdm.tqdm(zip(vocab.itos, embedding)):\n",
    "            \n",
    "            # skip words with unicode symbols\n",
    "            if len(word) != len(word.encode()):\n",
    "                continue\n",
    "            \n",
    "            # 'words' like \" \" or \"\\n\" fail to be loaded\n",
    "            if word.strip() == \"\":\n",
    "                continue\n",
    "\n",
    "            f.write(f\"{word} {' '.join(str(e) for e in vector.tolist())}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_context(model, field, path_model, path_vocab, cache_embeddings=\"cache_embeddings\", device=DEVICE):\n",
    "    \n",
    "    _vectors = torchtext.vocab.Vectors(path_vocab, cache_embeddings)  # voir unk_init\n",
    "    field.build_vocab(data_train, max_size=VOCAB_MAX_SIZE, vectors=_vectors)\n",
    "    \n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    \n",
    "    model.embedding.weight.data.copy_(field.vocab.vectors)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    iter_train, iter_valid, iter_test = \\\n",
    "        torchtext.data.BucketIterator.splits(datasets=(data_train, data_valid, data_test),\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             device=DEVICE,\n",
    "                                             sort_within_batch=True,\n",
    "                                             sort_key=lambda example: len(example.input),\n",
    "                                             sort=False)\n",
    "    \n",
    "    return model, (iter_train, iter_valid, iter_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_for_pred(folder_path, model, itos):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    torch.save(model.state_dict(), os.path.join(folder_path, \"model.pt\"))\n",
    "    with open(os.path.join(folder_path, \"itos\"), \"wb\") as f:\n",
    "        pickle.dump(itos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_for_pred(folder_path, model, device=DEVICE):\n",
    "    model.load_state_dict(torch.load(os.path.join(folder_path, \"model.pt\")))\n",
    "    model = model.to(DEVICE)\n",
    "    with open(os.path.join(folder_path, \"itos\"), \"rb\") as f:\n",
    "        itos = pickle.load(f)\n",
    "    stoi = collections.defaultdict(lambda: 0)\n",
    "    stoi.update(map(lambda t: t[::-1], enumerate(itos)))\n",
    "    return model, itos, stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = []\n",
    "N_EPOCHS = 10\n",
    "\n",
    "for hidden_dim, n_layers in itertools.product([512], [4]):\n",
    "    train_sets.append(TrainSet(\n",
    "        model=default_model(hidden_dim=hidden_dim, n_layers=n_layers),\n",
    "        name=f\"rnn_hidden-{hidden_dim}_nlayers-{n_layers}_nepochs-{N_EPOCHS}\",\n",
    "        iter_train=iter_train,\n",
    "        iter_valid=iter_valid,\n",
    "        fun_optimizer=torch.optim.Adam,\n",
    "        fun_criterion=torch.nn.MSELoss,\n",
    "        fun_train=train,\n",
    "        fun_eval=evaluate,\n",
    "        n_epochs=N_EPOCHS\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_set in train_sets:\n",
    "    train_set.init()\n",
    "    train_info = train_set.do_training()\n",
    "    \n",
    "    train_info.save(f\"info_{train_set.name}.pickle\")\n",
    "    \n",
    "    # plot loss data\n",
    "    fig, ax = plt.subplots(figsize=(20, 8))\n",
    "    ax_train = ax.plot(list(range(train_set.n_epochs)), train_info.train[\"loss\"], label=\"train\")\n",
    "    ax_valid = ax.plot(list(range(train_set.n_epochs)), train_info.valid[\"loss\"], label=\"valid\")\n",
    "    fig.legend()\n",
    "    fig.suptitle(\"Validation loss\")\n",
    "    plt.show()\n",
    "    \n",
    "    # save\n",
    "    save_vocab_embedding(\"vocab_emb\", TEXT.vocab, model.embedding.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peeking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tokens(tokens, model, stoi=TEXT.vocab.stoi, device=DEVICE):\n",
    "    model.eval()\n",
    "    idxs = [stoi[t] for t in tokens]\n",
    "    inp = torch.LongTensor(idxs).reshape(-1, 1).to(device)\n",
    "    output = output_to_pred(model((inp, torch.LongTensor([len(tokens)]))))\n",
    "    return output.item()\n",
    "\n",
    "\n",
    "def predict(sentence, model, stoi):\n",
    "    return predict_tokens(list(map(str, nlp.tokenizer(sentence))), model, stoi)\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model, stoi, device=DEVICE):\n",
    "        self.model = model\n",
    "        self.stoi = stoi\n",
    "        self.device = device\n",
    "    \n",
    "    def predict(self, sentence):\n",
    "        return predict(sentence, self.model, self.stoi)\n",
    "    \n",
    "    def predict_tokens(self, tokens):\n",
    "        return predict_tokens(tokens, self.model, self.stoi, self.device)\n",
    "    \n",
    "    def __call__(self, sentence):\n",
    "        return self.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, itos, stoi = load_for_pred(\"testsave\", default_model(hidden_dim=512, n_layers=4))\n",
    "predictor = Predictor(model, stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5, 4.0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor(\"Un mauvais film.\"), \\\n",
    "predictor(\"Un bon film.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un peintre et un jardinier refont le monde ... zzzzz ... pas le cinéma !\n",
      "true) 2.0 - 3.5 (pred\n",
      "( ... ) vrai - faux voyeurisme aussi spectaculaire sur le papier qu' il ne l' est pas sur l' écran . Un comble pour un film baptisé Les Acteurs qui regroupe ce qui se fait de mieux en la matière . Blier a tout écrit , il ne leur reste plus rien à faire .\n",
      "true) 3.0 - 2.0 (pred\n",
      "Le film , qui parle de survie , de rédemption , d' humanité retrouvée , ménage des scènes de déminage sous très haute tension . De celles que l' on n' est pas près d' oublier .\n",
      "true) 4.0 - 4.5 (pred\n"
     ]
    }
   ],
   "source": [
    "for example in random.sample(list(data_train), 3):\n",
    "    tokens, note = example.input, float(example.target)\n",
    "    print(\" \".join(tokens))\n",
    "    print(f\"true) {note * 5} - {predictor.predict_tokens(tokens)} (pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg number of <unk> per sentence: 0.03793992844662618\n"
     ]
    }
   ],
   "source": [
    "unks = sents = 0\n",
    "for batch in iter_train:\n",
    "    sentences = batch.input[0]\n",
    "    unks += (sentences == 0).sum().item()\n",
    "    sents += batch.batch_size\n",
    "print(f\"avg number of <unk> per sentence: {unks / sents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allergiques', 'alourdie', 'alter', 'altérité', 'amoral', 'anciennes', 'angles', 'aperçoit', 'appels', 'apportant']\n",
      "['durs', 'dynamiter', 'dystopie', 'débiles', 'débrouille', 'débutants', 'décadent', 'décapante', 'déchiré', 'décorative']\n"
     ]
    }
   ],
   "source": [
    "print(itos[10000:10010])\n",
    "print(TEXT.vocab.itos[10000:10010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = set(itos).symmetric_difference(TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18698"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looser accuracies for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the model really doing bad if it predicts a 4.5 instead of a 5 ? There are at least two ways to allow for forgivable divergence with the test data :\n",
    "* decrease notation's granularity, e.g. tranform the marks into good/bad, or good/bad/neutral.\n",
    "* consider a prediction correct if it belongs to a 'small' interval containing the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good/Neutral/Bad prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_to_3_way(pred_tensor, bad_treshold=.375, good_treshold=.625):\n",
    "    \"\"\"np array with values: 0: bad, 1: neutral, 2: good\"\"\"\n",
    "    return np.digitize(pred_tensor.cpu().detach().numpy(), [bad_treshold, good_treshold])\n",
    "    \n",
    "def eval_accuracy_3w(model, iterator):\n",
    "    n_examples = 0\n",
    "    n_success = 0\n",
    "    for batch in iterator:\n",
    "        predictions = model(batch.input).squeeze(1)\n",
    "        n_examples += len(batch)\n",
    "        n_success += sum(normalized_to_3_way(predictions) == normalized_to_3_way(batch.target))\n",
    "    return n_success / n_examples\n",
    "\n",
    "def classif_report_3w(model, iterator):\n",
    "    def preds_and_trues_to_array(predictions, true_targets):\n",
    "        return np.concatenate([normalized_to_3_way(true_targets).reshape(-1, 1),\n",
    "                               normalized_to_3_way(predictions).reshape(-1, 1)], axis=1)\n",
    "    \n",
    "    array = None\n",
    "    for batch in iterator:\n",
    "        predictions = model(batch.input).squeeze(1)\n",
    "        \n",
    "        if array is None:\n",
    "            array = preds_and_trues_to_array(predictions, batch.target)\n",
    "        else:\n",
    "            array = np.concatenate([array,\n",
    "                                    preds_and_trues_to_array(predictions, batch.target)], axis=0)\n",
    "    print(sklearn.metrics.classification_report(array[:, 0],\n",
    "                                                array[:, 1],\n",
    "                                                labels=[0, 1, 2],\n",
    "                                                target_names=[\"bad\", \"neutral\", \"good\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.11      0.08      0.09      1651\n",
      "     neutral       0.47      0.37      0.41      9738\n",
      "        good       0.51      0.63      0.57     10687\n",
      "\n",
      "    accuracy                           0.47     22076\n",
      "   macro avg       0.36      0.36      0.36     22076\n",
      "weighted avg       0.46      0.47      0.46     22076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterator = iter_test\n",
    "\n",
    "classif_report_3w(model, iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy_fuzzy(model, iterator, fuzziness=.1):\n",
    "    n_examples = 0.\n",
    "    n_success = 0.\n",
    "    for batch in iterator:\n",
    "        predictions = model(batch.input).squeeze(1)\n",
    "        n_examples += len(batch)\n",
    "        n_success += sum(torch.abs(predictions - batch.target) <= fuzziness).item()\n",
    "    return n_success / n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy_fuzzy(model, iter_test, fuzziness=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
