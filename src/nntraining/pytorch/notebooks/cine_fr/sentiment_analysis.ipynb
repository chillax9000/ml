{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import numpy as np\n",
    "import operator\n",
    "import simpleclock\n",
    "import sklearn.metrics\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.abspath(''), \"data_cine_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(tokenize = \"spacy\",\n",
    "                            tokenizer_language=\"fr_core_news_sm\",\n",
    "                            include_lengths=True)\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.float, use_vocab=False, preprocessing=lambda x: float(x) / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchtext.data.TabularDataset(path=data_path,\n",
    "                                        format=\"CSV\",\n",
    "                                        fields={\"critique\": (\"input\", TEXT), \"note\": (\"target\", LABEL)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = data_train.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"training data: {len(data_train)} examples.\n",
    "validation data: {len(data_valid)} examples.\n",
    "test data: {len(data_test)} examples.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torchtext.vocab.Vectors(\"cc.fr.300.vec\", os.path.join(os.path.expanduser(\"~\"), \"Downloads\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_MAX_SIZE = 50000\n",
    "TEXT.build_vocab(data_train, max_size=VOCAB_MAX_SIZE, vectors=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train, iter_valid, iter_test = \\\n",
    "    torchtext.data.BucketIterator.splits(datasets=(data_train, data_valid, data_test),\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         device=DEVICE,\n",
    "                                         sort_within_batch=True,\n",
    "                                         sort_key=lambda example: len(example.input),\n",
    "                                         sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, n_vocab, embedding_dim, hidden_dim, output_dim, dropout, bidirectional,\n",
    "                 n_layers, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        num_dir = 2 if bidirectional else 1\n",
    "        self.embedding = torch.nn.Embedding(n_vocab, embedding_dim, padding_idx=pad_idx)\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim,\n",
    "                                 bidirectional=bidirectional,\n",
    "                                 num_layers=n_layers)\n",
    "        self.fc = torch.nn.Linear(hidden_dim * num_dir, output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_lengths):\n",
    "        input, lengths = input_lengths\n",
    "        torch.nn.utils.rnn.pack_padded_sequence(input, lengths)\n",
    "        embedded = self.embedding(input)  # ((sent_len, batch), emb_dim)\n",
    "        packed_output, (hidden, cell) = self.rnn(embedded)  # hidden: (num_layers * num_directions,\n",
    "                                                            #          batch, hidden_size * num_directions)\n",
    "        hidden = (torch.cat([hidden[-2, :, :], hidden[-1, :, :]], dim=1)\n",
    "                  if self.bidirectional else hidden).squeeze(0)  # (batch, hidden_size * num_directions)\n",
    "        return self.sigmoid(self.fc(self.dropout(hidden)))  # (batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "DEFAULT_PARAMS = {\n",
    "    \"n_vocab\": len(TEXT.vocab),\n",
    "    \"embedding_dim\": 300,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"output_dim\": 1,\n",
    "    \"dropout\": 0.5,\n",
    "    \"bidirectional\": True,\n",
    "    \"n_layers\": 1,\n",
    "    \"pad_idx\": PAD_IDX,\n",
    "}\n",
    "\n",
    "def default_model(**kwargs):\n",
    "    _d = {}\n",
    "    _d.update(DEFAULT_PARAMS)\n",
    "    _d.update(kwargs)\n",
    "    return RNN(**_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_init(model, criterion, device=DEVICE, learn_embedding_param=True):\n",
    "    model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(model.embedding_dim)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(model.embedding_dim)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if name == \"embedding.weight\":\n",
    "            param.requires_grad = learn_embedding_param\n",
    "    print(\"The model has {:,} trainable parameters\"\n",
    "         .format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    return model, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_pred(output):\n",
    "    return (output * 10).round() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    correct = (preds == y).float()  # convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch.input).squeeze(1)\n",
    "        loss = criterion(output, batch.target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = accuracy(output_to_pred(output), batch.target * 5)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "      \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            output = model(batch.input).squeeze(1)\n",
    "            loss = criterion(output, batch.target)\n",
    "            acc = accuracy(output_to_pred(output), batch.target * 5)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainInfo:\n",
    "    def __init__(self, valid={}, train={}):\n",
    "        self.valid = collections.defaultdict(lambda: [])\n",
    "        self.valid.update(valid)\n",
    "        self.train = collections.defaultdict(lambda: [])\n",
    "        self.train.update(train)\n",
    "    \n",
    "    def save(self, path):\n",
    "        packed = {\n",
    "            \"valid\": dict(self.valid),\n",
    "            \"train\": dict(self.train),\n",
    "        }\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(packed, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            packed = pickle.load(f)\n",
    "            return cls(valid=packed[\"valid\"],\n",
    "                       train=packed[\"train\"])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _dict_to_repr(d):\n",
    "        return dict(map(lambda k_v: (k_v[0], f\"{len(k_v[1])} elements\"), d.items()))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return pprint.pformat({\"valid\": self._dict_to_repr(self.valid),\n",
    "                     \"train\": self._dict_to_repr(self.train),})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(model, name, iter_train, iter_valid, optimizer, criterion, fun_train,\n",
    "                fun_eval, n_epochs=100, train_info=None):\n",
    "\n",
    "    clock = simpleclock.Clock.started()\n",
    "    torch.cuda.empty_cache()\n",
    "    train_info = train_info if train_info is not None else TrainInfo()\n",
    "    best_valid_loss = min(train_info.valid[\"loss\"]) if train_info.valid[\"loss\"] else float(\"inf\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        clock.elapsed_since_start.call()  # meh\n",
    "\n",
    "        train_loss, train_acc = fun_train(model, iter_train, optimizer, criterion)\n",
    "        valid_loss, valid_acc = fun_eval(model, iter_valid, criterion)\n",
    "\n",
    "        clock.elapsed_since_last_call.print(\n",
    "            f\"Epoch: {epoch+1:<3}. T, V acc: {100 * train_acc:.1f}%, {100 * valid_acc:.1f}%. Took\")\n",
    "        train_info.train[\"loss\"].append(train_loss)\n",
    "        train_info.valid[\"loss\"].append(valid_loss)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f\"{name}.pt\")\n",
    "\n",
    "    clock.elapsed_since_start.print(f\"Trained {name}, {n_epochs} epochs, for\")\n",
    "    return train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSet:\n",
    "    def __init__(self, model, name, iter_train, iter_valid,\n",
    "                 fun_optimizer, fun_criterion, fun_train, fun_eval,\n",
    "                 device=DEVICE, n_epochs=100):\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.iter_train = iter_train\n",
    "        self.iter_valid = iter_valid\n",
    "        self.fun_optimizer = fun_optimizer\n",
    "        self.fun_criterion = fun_criterion\n",
    "        self.fun_train = fun_train\n",
    "        self.fun_eval = fun_eval\n",
    "        self.n_epochs = n_epochs\n",
    "        self.device = device\n",
    "        \n",
    "        self.optimizer = None\n",
    "        self.criterion = None\n",
    "        \n",
    "    def init(self, learn_embedding_param=True):\n",
    "        self.model, self.criterion = pseudo_init(self.model, self.fun_criterion(), self.device,\n",
    "                                                 learn_embedding_param=learn_embedding_param)\n",
    "        self.optimizer = self.fun_optimizer(self.model.parameters())\n",
    "    \n",
    "    def do_training(self):\n",
    "        if self.optimizer is None or self.criterion is None:\n",
    "            raise Exception(\"It looks like an init is needed: optimizer or criterion is None\")\n",
    "        return do_training(model=self.model,\n",
    "                           name=self.name,\n",
    "                           iter_train=self.iter_train,\n",
    "                           iter_valid=self.iter_valid,\n",
    "                           optimizer=self.optimizer,\n",
    "                           criterion=self.criterion,\n",
    "                           fun_train=self.fun_train,\n",
    "                           fun_eval=self.fun_eval,\n",
    "                           n_epochs=self.n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = []\n",
    "\n",
    "for hidden_dim, n_layers in itertools.product([128], [7]):\n",
    "    train_sets.append(TrainSet(\n",
    "        model=default_model(hidden_dim=hidden_dim, n_layers=n_layers),\n",
    "        name=f\"rnn_hidden-{hidden_dim}_nlayers-{n_layers}\",\n",
    "        iter_train=iter_train,\n",
    "        iter_valid=iter_valid,\n",
    "        fun_optimizer=torch.optim.Adam,\n",
    "        fun_criterion=torch.nn.MSELoss,\n",
    "        fun_train=train,\n",
    "        fun_eval=evaluate,\n",
    "        n_epochs=10\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_set in train_sets:\n",
    "    train_set.init()\n",
    "    train_info = train_set.do_training()\n",
    "    \n",
    "    train_info.save(f\"info_{train_set.name}.pickle\")\n",
    "    \n",
    "    # plot loss data\n",
    "    fig, ax = plt.subplots(figsize=(20, 8))\n",
    "    ax_train = ax.plot(list(range(train_set.n_epochs)), train_info.train[\"loss\"], label=\"train\")\n",
    "    ax_valid = ax.plot(list(range(train_set.n_epochs)), train_info.valid[\"loss\"], label=\"valid\")\n",
    "    fig.legend()\n",
    "    fig.suptitle(\"Validation loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peeking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tokens(tokens, model, device=DEVICE):\n",
    "    model.eval()\n",
    "    idxs = [TEXT.vocab.stoi[t] for t in tokens]\n",
    "    inp = torch.LongTensor(idxs).reshape(-1, 1).to(device)\n",
    "    output = output_to_pred(model((inp, torch.LongTensor([len(tokens)]))))\n",
    "    return output.item()\n",
    "\n",
    "\n",
    "def predict(sentence, model):\n",
    "    return predict_tokens(list(map(str, nlp.tokenizer(sentence))), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = default_model(hidden_dim=128, n_layers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('rnn_hidden-128_nlayers-5.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Du temps perdu.\", model), \\\n",
    "predict(\"Un très bon film, à voir avec toute la famille.\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in random.sample(list(data_test), 3):\n",
    "    tokens, note = example.input, float(example.target)\n",
    "    print(\" \".join(tokens))\n",
    "    print(f\"true) {note * 5} - {predict_tokens(tokens, model)} (pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing predictions on extremal marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the model really doing bad if it predicts a 4.5 instead of a 5 ? There are at least two ways to allow for forgivable divergence with the test data :\n",
    "* decrease notation's granularity, e.g. tranform the marks into good/bad, or good/bad/neutral.\n",
    "* consider a prediction correct if it belongs to a 'small' interval containing the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good/Neutral/Bad prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_to_3_way(pred_tensor, bad_treshold=.4, good_treshold=.6):\n",
    "    \"\"\"np array with values: 0: bad, 1: neutral, 2: good\"\"\"\n",
    "    return np.digitize(pred_tensor.cpu().detach().numpy(), [bad_treshold, good_treshold])\n",
    "    \n",
    "def eval_accuracy_3w(model, iterator):\n",
    "    n_examples = 0\n",
    "    n_success = 0\n",
    "    for batch in iterator:\n",
    "        predictions = model(batch.input).squeeze(1)\n",
    "        n_examples += len(batch)\n",
    "        n_success += sum(normalized_to_3_way(predictions) == normalized_to_3_way(batch.target))\n",
    "    return n_success / n_examples\n",
    "\n",
    "def classif_report_3w(model, iterator):\n",
    "    def preds_and_trues_to_array(predictions, true_targets):\n",
    "        return np.concatenate([mark_to_3_way(true_targets).reshape(-1, 1),\n",
    "                               pred_to_3_way(predictions).reshape(-1, 1)], axis=1)\n",
    "    \n",
    "    array = None\n",
    "    for batch in iterator:\n",
    "        predictions = model(batch.input).squeeze(1)\n",
    "        \n",
    "        if array is None:\n",
    "            array = preds_and_trues_to_array(predictions, batch.target)\n",
    "        else:\n",
    "            array = np.concatenate([array,\n",
    "                                    preds_and_trues_to_array(predictions, batch.target)], axis=0)\n",
    "    print(sklearn.metrics.classification_report(array[:, 0],\n",
    "                                                array[:, 1],\n",
    "                                                labels=[0, 1, 2],\n",
    "                                                target_names=[\"bad\", \"neutral\", \"good\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter_test\n",
    "\n",
    "classif_report_3w(model, iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy_fuzzy(model, iterator, fuzziness=.1):\n",
    "    n_examples = 0.\n",
    "    n_success = 0.\n",
    "    for batch in iterator:\n",
    "        predictions = model(batch.input).squeeze(1)\n",
    "        n_examples += len(batch)\n",
    "        n_success += sum(torch.abs(predictions - batch.target) <= fuzziness).item()\n",
    "    return n_success / n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy_fuzzy(model, iter_test, fuzziness=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
