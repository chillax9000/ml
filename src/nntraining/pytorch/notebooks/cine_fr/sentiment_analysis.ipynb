{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import numpy as np\n",
    "import operator\n",
    "import simpleclock\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.abspath(''), \"data_cine_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(tokenize = \"spacy\",\n",
    "                            tokenizer_language=\"fr_core_news_sm\",\n",
    "                            include_lengths=True)\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.float, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchtext.data.TabularDataset(path=data_path,\n",
    "                                        format=\"CSV\",\n",
    "                                        fields={\"critique\": (\"critique\", TEXT), \"note\": (\"note\", LABEL)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = data_train.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 36057 examples.\n",
      "validation data: 15453 examples.\n",
      "test data: 22076 examples.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"training data: {len(data_train)} examples.\n",
    "validation data: {len(data_valid)} examples.\n",
    "test data: {len(data_test)} examples.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torchtext.vocab.Vectors(\"cc.fr.300.vec\", os.path.join(os.path.expanduser(\"~\"), \"Downloads\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_MAX_SIZE = 50000\n",
    "TEXT.build_vocab(data_train, max_size=VOCAB_MAX_SIZE, vectors=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train, iter_valid, iter_test = \\\n",
    "    torchtext.data.BucketIterator.splits(datasets=(data_train, data_valid, data_test),\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         device=device,\n",
    "                                         sort_within_batch=True,\n",
    "                                         sort_key=lambda example: len(example.critique),\n",
    "                                         sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, n_vocab, embedding_dim, hidden_dim, output_dim, dropout, bidirectional,\n",
    "                 n_layers, pad_idx):\n",
    "        super().__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        num_dir = 2 if bidirectional else 1\n",
    "        self.embedding = torch.nn.Embedding(n_vocab, embedding_dim, padding_idx=pad_idx)\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim,\n",
    "                                 bidirectional=bidirectional,\n",
    "                                 num_layers=n_layers)\n",
    "        self.fc = torch.nn.Linear(hidden_dim * num_dir, output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input, lengths):\n",
    "        torch.nn.utils.rnn.pack_padded_sequence(input, lengths)\n",
    "        embedded = self.embedding(input)  # ((sent_len, batch), emb_dim)\n",
    "        packed_output, (hidden, cell) = self.rnn(embedded)  # hidden: (num_layers * num_directions,\n",
    "                                                            #          batch, hidden_size * num_directions)\n",
    "        hidden = (torch.cat([hidden[-2, :, :], hidden[-1, :, :]], dim=1)\n",
    "                  if self.bidirectional else hidden).squeeze(0)  # (batch, hidden_size * num_directions)\n",
    "        return self.sigmoid(self.fc(self.dropout(hidden)))  # (batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_VOCAB = len(TEXT.vocab)\n",
    "# EMBEDDING_DIM = 300\n",
    "# HIDDEN_DIM = 256\n",
    "# OUTPUT_DIM = 1\n",
    "# DROPOUT = 0.5\n",
    "# BIDIRECTIONAL = True\n",
    "# N_LAYERS = 1\n",
    "# PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "# UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "# def default_model(\n",
    "#     n_vocab=N_VOCAB,\n",
    "#     embedding_dim=EMBEDDING_DIM,\n",
    "#     hidden_dim=HIDDEN_DIM,\n",
    "#     output_dim=OUTPUT_DIM,\n",
    "#     dropout=DROPOUT,\n",
    "#     pad_idx=PAD_IDX,\n",
    "#     bidirectional=BIDIRECTIONAL,\n",
    "#     n_layers=N_LAYERS,\n",
    "# ): \n",
    "#     return RNN(\n",
    "#         n_vocab=n_vocab,\n",
    "#         embedding_dim=embedding_dim,\n",
    "#         hidden_dim=hidden_dim,\n",
    "#         output_dim=output_dim,\n",
    "#         dropout=dropout,\n",
    "#         pad_idx=pad_idx,\n",
    "#         bidirectional=bidirectional,\n",
    "#         n_layers=n_layers,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "DEFAULT_PARAMS = {\n",
    "    \"n_vocab\": len(TEXT.vocab),\n",
    "    \"embedding_dim\": 300,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"output_dim\": 1,\n",
    "    \"dropout\": 0.5,\n",
    "    \"bidirectional\": True,\n",
    "    \"n_layers\": 1,\n",
    "    \"pad_idx\": PAD_IDX,\n",
    "}\n",
    "\n",
    "def default_model(**kwargs):\n",
    "    _d = {}\n",
    "    _d.update(DEFAULT_PARAMS)\n",
    "    _d.update(kwargs)\n",
    "    return RNN(**_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_init(model, criterion, device=device, learn_embedding_param=True):\n",
    "    model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if name == \"embedding.weight\":\n",
    "            param.requires_grad = learn_embedding_param\n",
    "    print(\"The model has {:,} trainable parameters\"\n",
    "         .format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    return model, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, criterion = pseudo_init(model, torch.nn.MSELoss(), learn_embedding_param=False)\n",
    "# optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_pred(output):\n",
    "    return (output * 10).round() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    correct = (preds == y).float()# convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        padded_sequences, lengths = batch.critique\n",
    "        output = model(padded_sequences, lengths).squeeze(1)\n",
    "        loss = criterion(output, batch.note / 5.)\n",
    "        acc = accuracy(output_to_pred(output), batch.note)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "      \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            padded_sequences, lengths = batch.critique\n",
    "            output = model(padded_sequences, lengths).squeeze(1)\n",
    "            loss = criterion(output, batch.note / 5.)\n",
    "            acc = accuracy(output_to_pred(output), batch.note)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainInfo:\n",
    "    def __init__(self, valid={}, train={}):\n",
    "        self.valid = collections.defaultdict(lambda: [])\n",
    "        self.valid.update(valid)\n",
    "        self.train = collections.defaultdict(lambda: [])\n",
    "        self.train.update(train)\n",
    "    \n",
    "    def save(self, path):\n",
    "        packed = {\n",
    "            \"valid\": dict(self.valid),\n",
    "            \"train\": dict(self.train),\n",
    "        }\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(packed, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            packed = pickle.load(f)\n",
    "            return cls(valid=packed[\"valid\"],\n",
    "                       train=packed[\"train\"])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _dict_to_repr(d):\n",
    "        return dict(map(lambda k_v: (k_v[0], f\"{len(k_v[1])} elements\"), d.items()))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return pprint.pformat({\"valid\": self._dict_to_repr(self.valid),\n",
    "                     \"train\": self._dict_to_repr(self.train),})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(model, name, iter_train, iter_valid, optimizer, criterion, fun_train,\n",
    "                fun_eval, n_epochs=100, train_info=None):\n",
    "\n",
    "    clock = simpleclock.Clock.started()\n",
    "    torch.cuda.empty_cache()\n",
    "    train_info = train_info if train_info is not None else TrainInfo()\n",
    "    best_valid_loss = min(train_info.valid[\"loss\"]) if train_info.valid[\"loss\"] else float(\"inf\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        clock.elapsed_since_start.call()  # meh\n",
    "\n",
    "        train_loss, train_acc = fun_train(model, iter_train, optimizer, criterion)\n",
    "        valid_loss, valid_acc = fun_eval(model, iter_valid, criterion)\n",
    "\n",
    "        clock.elapsed_since_last_call.print(f\"Epoch: {epoch+1:02} | Epoch Time\")\n",
    "        train_info.train[\"loss\"].append(train_loss)\n",
    "        train_info.valid[\"loss\"].append(valid_loss)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f\"{name}.pt\")\n",
    "\n",
    "    clock.elapsed_since_start.print(f\"Trained {name}, {n_epochs} epochs, for\")\n",
    "    return train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSet:\n",
    "    def __init__(self, model, name, iter_train, iter_valid,\n",
    "                 fun_optimizer, fun_criterion, fun_train, fun_eval,\n",
    "                 device=DEVICE, n_epochs=100):\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.iter_train = iter_train\n",
    "        self.iter_valid = iter_valid\n",
    "        self.fun_optimizer = fun_optimizer\n",
    "        self.optimizer = None\n",
    "        self.fun_criterion = fun_criterion\n",
    "        self.criterion = None\n",
    "        self.fun_train = fun_train\n",
    "        self.fun_eval = fun_eval\n",
    "        self.n_epochs = n_epochs\n",
    "        self.device = device\n",
    "    \n",
    "    def init(self, learn_embedding_param=True):\n",
    "        self.model, self.criterion = pseudo_init(self.model, self.fun_criterion(), self.device,\n",
    "                                                 learn_embedding_param=learn_embedding_param)\n",
    "        self.optimizer = self.fun_optimizer(self.model.parameters())\n",
    "    \n",
    "    def do_training(self):\n",
    "        return do_training(model=self.model,\n",
    "                           name=self.name,\n",
    "                           iter_train=self.iter_train,\n",
    "                           iter_valid=self.iter_valid,\n",
    "                           optimizer=self.optimizer,\n",
    "                           criterion=self.criterion,\n",
    "                           fun_train=self.fun_train,\n",
    "                           fun_eval=self.fun_eval,\n",
    "                           n_epochs=self.n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = []\n",
    "\n",
    "for hidden_dim in [128, 256, 512]:\n",
    "    train_sets.append(TrainSet(\n",
    "        model=default_model(hidden_dim=hidden_dim),\n",
    "        name=f\"rnn_hidden-{hidden_dim}\",\n",
    "        iter_train=iter_train,\n",
    "        iter_valid=iter_valid,\n",
    "        fun_optimizer=torch.optim.Adam,\n",
    "        fun_criterion=torch.nn.MSELoss,\n",
    "        fun_train=train,\n",
    "        fun_eval=evaluate,\n",
    "        n_epochs=5\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,441,177 trainable parameters\n",
      "Epoch: 01 | Epoch Time: 2.59s\n",
      "Epoch: 02 | Epoch Time: 2.57s\n",
      "Epoch: 03 | Epoch Time: 2.59s\n",
      "Epoch: 04 | Epoch Time: 2.57s\n",
      "Epoch: 05 | Epoch Time: 2.57s\n",
      "Total time: 13.38s\n",
      "The model has 16,143,897 trainable parameters\n",
      "Epoch: 01 | Epoch Time: 4.03s\n",
      "Epoch: 02 | Epoch Time: 4.02s\n",
      "Epoch: 03 | Epoch Time: 3.99s\n",
      "Epoch: 04 | Epoch Time: 4.01s\n",
      "Epoch: 05 | Epoch Time: 3.99s\n",
      "Total time: 20.41s\n",
      "The model has 18,335,769 trainable parameters\n",
      "Epoch: 01 | Epoch Time: 7.90s\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for train_set in train_sets:\n",
    "    train_set.init()\n",
    "    train_info = train_set.do_training()\n",
    "    \n",
    "    #ax_train = ax.plot(list(range(train_set.n_epochs)), train_info.train[\"loss\"], label=\"train\")\n",
    "    ax_valid = ax.plot(list(range(train_set.n_epochs)), train_info.valid[\"loss\"],\n",
    "                       label=f\"{train_set.name}\")\n",
    "fig.legend()\n",
    "fig.suptitle(\"Validation loss\")\n",
    "plt.savefig(f\"loss_valid.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peeking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tokens(tokens, model):\n",
    "    model.eval()\n",
    "    idxs = [TEXT.vocab.stoi[t] for t in tokens]\n",
    "    inp = torch.LongTensor(idxs).reshape(-1, 1).to(device)\n",
    "    output = output_to_pred(model(inp, torch.LongTensor([len(tokens)])))\n",
    "    return output.item()\n",
    "\n",
    "\n",
    "def predict(sentence, model):\n",
    "    return predict_tokens(list(map(str, nlp.tokenizer(sentence))), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_rnn_hidden-512.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5, 4.0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Du temps perdu.\", model), \\\n",
    "predict(\"Un très bon film, à voir avec toute la famille.\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bouleversant , parfois dérangeant . Inoubliable , en tout cas .\n",
      "true) 4.0 - 4.0 (pred\n",
      "On attendait ce volume 3 avec impatience et on n' est pas déçu . Les petits se gondolent , les plus grands aussi .\n",
      "true) 3.0 - 3.5 (pred\n",
      "Malgré un scénario faiblard et une longueur éprouvante , \" Transformers 4 : L' Âge de l' extinction \" ne s' en sort pas trop mal grâce au renouveau du casting , l' introduction des Dinobots , et l' ahurissante mise en scène du maître artificier Michael Bay .\n",
      "true) 3.0 - 1.5 (pred\n"
     ]
    }
   ],
   "source": [
    "for example in random.sample(list(data_test), 3):\n",
    "    tokens, note = example.critique, float(example.note)\n",
    "    print(\" \".join(tokens))\n",
    "    print(f\"true) {note} - {predict_tokens(tokens, model)} (pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing predictions on extremal marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the model really doing bad if it predicts a 4.5 instead of a 5 ? There are at least two ways to allow for forgivable divergence with the test data :\n",
    "* decrease notation's granularity, e.g. tranform the marks into good/bad, or good/bad/neutral.\n",
    "* consider a prediction correct if it belongs to a 'small' interval containing the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good/Neutral/Bad prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_to_3_way(mark_tensor, bad_treshold=2, good_treshold=3.5):\n",
    "    \"\"\"np array with values: 0: bad, 1: neutral, 2: good\"\"\"\n",
    "    return np.digitize(mark_tensor.cpu().detach().numpy(), [bad_treshold, good_treshold])\n",
    "\n",
    "def pred_to_3_way(pred_tensor, bad_treshold=0.4, good_treshold=0.651):\n",
    "    \"\"\"np array with values: 0: bad, 1: neutral, 2: good\"\"\"\n",
    "    return np.digitize(pred_tensor.cpu().detach().numpy(), [bad_treshold, good_treshold])\n",
    "    \n",
    "def eval_accuracy_3w(model, iterator):\n",
    "    n_examples = 0\n",
    "    n_success = 0\n",
    "    for batch in iterator:\n",
    "        padded_sequences, lengths = batch.critique\n",
    "        predictions = model(padded_sequences, lengths).squeeze(1)\n",
    "        n_examples += len(batch)\n",
    "        n_success += sum(pred_to_3_way(predictions) == mark_to_3_way(batch.note))\n",
    "    return n_success / n_examples\n",
    "\n",
    "def classif_report_3w(model, iterator):\n",
    "    def preds_and_trues_to_array(predictions, true_notes):\n",
    "        return np.concatenate([mark_to_3_way(true_notes).reshape(-1, 1),\n",
    "                               pred_to_3_way(predictions).reshape(-1, 1)], axis=1)\n",
    "    \n",
    "    array = None\n",
    "    for batch in iterator:\n",
    "        padded_sequences, lengths = batch.critique\n",
    "        predictions = model(padded_sequences, lengths).squeeze(1)\n",
    "        \n",
    "        if array is None:\n",
    "            array = preds_and_trues_to_array(predictions, batch.note)\n",
    "        else:\n",
    "            array = np.concatenate([array,\n",
    "                                    preds_and_trues_to_array(predictions, batch.note)], axis=0)\n",
    "    print(sklearn.metrics.classification_report(array[:, 0],\n",
    "                                                array[:, 1],\n",
    "                                                labels=[0, 1, 2],\n",
    "                                                target_names=[\"bad\", \"neutral\", \"good\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.30      0.48      0.37      1688\n",
      "     neutral       0.65      0.48      0.55      9696\n",
      "        good       0.72      0.82      0.77     10692\n",
      "\n",
      "    accuracy                           0.65     22076\n",
      "   macro avg       0.56      0.59      0.56     22076\n",
      "weighted avg       0.66      0.65      0.64     22076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterator = iter_test\n",
    "\n",
    "classif_report_3w(model, iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy_fuzzy(model, iterator, fuzziness=.5):\n",
    "    n_examples = 0.\n",
    "    n_success = 0.\n",
    "    for batch in iterator:\n",
    "        padded_sequences, lengths = batch.critique\n",
    "        predictions = model(padded_sequences, lengths).squeeze(1)\n",
    "        n_examples += len(batch)\n",
    "        n_success += sum(torch.abs(output_to_pred(predictions) - batch.note) <= fuzziness).item()\n",
    "    return n_success / n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy_fuzzy(model, iter_test, fuzziness=.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
